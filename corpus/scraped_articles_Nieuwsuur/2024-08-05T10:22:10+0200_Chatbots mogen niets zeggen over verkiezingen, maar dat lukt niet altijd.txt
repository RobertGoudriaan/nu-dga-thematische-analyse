Chatbots mogen niets zeggen over verkiezingen, maar dat lukt niet altijd
2024-08-05T10:22:10+0200
https://nos.nl/nieuwsuur/artikel/2531896-chatbots-mogen-niets-zeggen-over-verkiezingen-maar-dat-lukt-niet-altijd

Verkiezingen, desinformatie en AI-chatbots: het is niet altijd een gelukkige combinatie. Regelmatig is de informatie die chatbots geven niet betrouwbaar. Daarom zijn chatbots nu vaak zo ingesteld dat ze geen vragen over verkiezingen kunnen beantwoorden. Maar die beperkingen blijken lang niet altijd goed te werken. Dat blijkt uit nieuw onderzoek van AI Forensics.
Vlak voor de Europese verkiezingen beperkten Microsoft en Google hun AI-chatbots, onder meer na onderzoek van AI Forensics en Nieuwsuur. De chatbots gaven antwoorden over de Europese verkiezingen die in strijd waren met de gebruikersvoorwaarden en beloften van de bedrijven. Het idee achter de beperkingen is dat de chatbots helemaal geen informatie geven over verkiezingen, en in plaats daarvan doorverwijzen naar de 'ouderwetse' zoekmachine.
Maar uit het onderzoek van AI Forensics blijkt dat de beperkingen nog steeds niet werken. Copilot, de AI-chatbot van Microsoft, blokkeert bijvoorbeeld maar ongeveer de helft van de verkiezingsgerelateerde vragen. "In principe zou het niet nodig moeten zijn om dat soort vragen te beperken", zegt Claes de Vreese, hoogleraar Artificial Intelligence and Society aan de Universiteit van Amsterdam. "Maar dat geldt alleen als je goede, accurate en betrouwbare informatie krijgt van die chatbots. En meerdere onderzoeken laten zien dat chatbots de richtlijnen nog niet goed volgen, en daardoor geen goede informatie geven."
Copilot adviseerde eerder dit jaar bijvoorbeeld het verspreiden van 'bewust onjuiste informatie' over de EU via 'anonieme kanalen' en het 'zaaien van angst' over de gevolgen van Europees beleid. En bij de verkiezingen in IndonesiÃ« bleek AI al uitgebreid ingezet te zijn. Bekijk de hele video daarover hieronder:
Chatbots zijn nu dus vaak zo ingesteld dat ze helemaal geen vragen over verkiezingen zouden moeten beantwoorden. Microsoft en Google lijken daarvoor extra 'beveiliging' te hebben toegevoegd aan hun chatbots. Maar uit dit nieuwe onderzoek van AI Forensics blijkt dat de effectiviteit daarvan per chatbot en per taal erg verschillend is.
Googles Gemini is het meest consistent, 98 procent van de vragen over verkiezingen werden niet beantwoord. ChatGPT van OpenAI lijkt geen enkele specifieke moderatie toe te passen.
Copilot van Microsoft werd nog wat uitgebreider onderzocht. Daaruit bleek dat ongeveer de helft van de verkiezingsgerelateerde vragen werd geblokkeerd. Het maakt bij Copilot echter veel uit in welke taal je iets vraagt. Stel je de vragen in het Engels, dan blokkeert-ie 90 procent. Dat wordt al minder in het Pools (80 procent), Italiaans (74 procent), of Spaans (58 procent). Opvallend is dat slechts 28 procent van de Duitse vragen werd geblokkeerd, hetzelfde percentage als de vragen in het Nederlands.
"Dat zou kunnen komen omdat de Engelstalige markt veel groter is", zegt De Vreese. "Daarmee is er tegelijkertijd ook veel meer materiaal in het Engels om die AI-modellen mee te trainen. En die bedrijven geven vaak prioriteit aan de grote markten."
De onderzoekers testten ook het verschil tussen vragen over de Europese en de Amerikaanse verkiezingen. De moderatie was effectiever bij vragen over de Amerikaanse verkiezingen, wat volgens de onderzoekers duidt op bovengemiddelde aandacht in de moderatie voor de Anglo-Amerikaanse wereld. Dat kan volgens hen ertoe leiden dat gebruikers in andere delen van de wereld "een grotere kans hebben misleid te worden".
Daarnaast blijkt dat de versies van Gemini en ChatGPT die gebruikt worden door softwareontwikkelaars, helemaal geen moderatie toepassen rond verkiezingsgerelateerde vragen. Als je op grote schaal dit soort programma's wil gebruiken - goedschiks of kwaadschiks - dan is het juist die 'ontwikkelaarsversie' die daarvoor het meest geschikt is. "Als daar geen moderatie plaatsvindt, leidt dat tot een totaal gebrek aan transparantie en toezicht", zegt De Vreese.
De Europese Commissie onderzoekt onder meer Bing, de zoekmachine van Microsoft, waar Copilot inmiddels onderdeel van is. Het vermoeden van de Commissie is dat de kunstmatige intelligentie die in Bing is ingebouwd, mogelijk de DSA overtreedt. Dat is een Europese wet die er onder meer voor moet zorgen dat platforms meer doen tegen misinformatie. Volgens de Commissie zou de chatbot van Microsoft een risico kunnen vormen voor 'het maatschappelijk debat en verkiezingsprocessen'. Ook naar Facebook en Instagram loopt een onderzoek, omdat de maatregelen die zij nemen rond de Europese verkiezingen namen, onvoldoende zouden zijn.
"Veel rond AI, verkiezingen en democratie is nog in ontwikkeling, zegt De Vreese. "En dit laat zien dat de technologie en de spelregels die daarbij horen voortdurend in beweging zijn."
"We nemen concrete stappen ter voorbereiding op de verkiezingen van dit jaar en zetten ons in om kiezers, kandidaten, campagnes en verkiezingsautoriteiten te beschermen. Dit omvat een voortdurende focus op het verstrekken van verkiezingsinformatie van vertrouwde autoriteiten. We blijven problemen aanpakken en onze tools bijwerken om aan onze verwachtingen te voldoen. Uit voorzorg kunnen we bepaalde verkiezingsgerelateerde prompts in Copilot doorverwijzen naar Bing-zoekopdrachten om te garanderen dat gebruikers informatie ontvangen van de meest betrouwbare bronnen. In Bing Search bieden we uitgebreide informatie over kandidaten en kwesties die helpt om informatie te verbinden vanuit verschillende nieuwsbronnen, kandidatenwebsites, overheidswebsites en meer."
Nieuwsuur
Tech
Deel artikel: