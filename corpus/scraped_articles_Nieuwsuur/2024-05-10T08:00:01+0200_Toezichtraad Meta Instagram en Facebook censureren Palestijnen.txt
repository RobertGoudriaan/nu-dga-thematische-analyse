Toezichtraad Meta: Instagram en Facebook censureren Palestijnen
2024-05-10T08:00:01+0200
https://nos.nl/nieuwsuur/artikel/2519918-toezichtraad-meta-instagram-en-facebook-censureren-palestijnen

Fleur Damen
redacteur-verslaggever Nieuwsuur
Roel van Niekerk
redacteur-verslaggever Nieuwsuur
Fleur Damen
redacteur-verslaggever Nieuwsuur
Roel van Niekerk
redacteur-verslaggever Nieuwsuur
Instagram en Facebook censureren Palestijnse en pro-Palestijnse gebruikers en doen onvoldoende om dat te verhelpen. Dat zegt de Meta Oversight Board, de toezichtraad van moederbedrijf Meta, in gesprek met Nieuwsuur.
Sinds het begin van de oorlog tussen Hamas en Israël melden met name (pro-)Palestijnse gebruikers van Instagram en Facebook een onverklaarbare afname van zichtbaarheid van hun berichten wanneer die over de Palestijnen gaan. Meta ontkent dat dat fenomeen, ook wel shadowbanning genoemd, bestaat.
Maar de toezichtraad is dus een andere mening toegedaan. "We hebben gezien hoe Meta berichten lager plaatst zodat het bereik ervan afneemt", zegt Nighat Dad, die vanaf het begin deel uitmaakt van de raad.
Dad voegt toe: "Wat wij het belangrijkst vinden: Meta heeft er geen duidelijk beleid over, en transparantie ontbreekt volledig. Daardoor weten gebruikers niet waar ze aan toe zijn."
Nieuwsuur dook in de ondoorzichtige wereld van contentmoderatie op Instagram en TikTok. Wat laten de bedrijven staan en wat halen ze weg over de oorlog tussen Hamas en Israël? Dat zie je in deze video:
De Meta Oversight Board wordt ook wel 'het Hooggerechtshof van Meta' genoemd. De raad kan Meta dwingen moderatiebeslissingen, zoals het verwijderen van berichten en accounts, terug te draaien. Ook geeft de raad advies aan het bedrijf.
De toezichtraad werd in 2020 door Meta zelf in het leven geroepen en wordt indirect door het bedrijf gefinancierd, via een stichting. De raad functioneert onafhankelijk en geeft vaker kritisch advies.
De toezichtraad is ook kritisch op het gebrek aan kennis van het Arabisch en van de context van het Israëlisch-Palestijnse conflict bij Meta. Zo kwam onlangs naar buiten dat de automatische vertaling van Instagram het woord "terrorist" toevoegde aan gebruikers die zichzelf omschreven als Palestijns in hun Instagram-profiel. Volgens Meta was dat een fout.
Maar die fout staat niet op zichzelf, benadrukt de raad. In het voorjaar van 2021 verwijderden Meta berichten met de term 'Al-Aqsa'. Medewerkers dachten dat de term verwees naar een Palestijnse terreurorganisatie, de Al-Aqsa Martelarenbrigade. Die staat op Meta's lijst met gevaarlijke personen en organisaties, bedoeld om berichten waarin terrorisme wordt verheerlijkt snel op te sporen en te verwijderen.
Maar gebruikers gebruikten de term volop om te verwijzen naar de Al Aqsa-moskee in Jeruzalem, een van de heiligste plekken in de islam. Daar viel op dat moment de Israëlische politie binnen. "We hebben het bedrijf de afgelopen jaren meermaals gevraagd te investeren in medewerkers die Arabisch spreken en het conflict snappen", zegt Dad. "Ze zouden onze aanbevelingen serieus moeten bekijken en ze op moeten volgen."
Die lijst met gevaarlijke personen en organisaties is sowieso problematisch, vindt de toezichtraad. Op basis van de lijst, die niet openbaar is, verwijdert Meta namelijk geautomatiseerd berichten waarin mensen en organisaties op de lijst worden genoemd. Maar die geautomatiseerde moderatie is slecht in het maken van onderscheid tussen neutrale berichten en berichten waarin terrorisme wordt verheerlijkt, zegt Dad.
Daardoor kunnen Palestijnse journalisten bijvoorbeeld geen nieuwsberichten over Hamas plaatsen zonder te vrezen voor beperkingen van hun account. De toezichtraad maakt zich daar zorgen om. "Mensen in het oorlogsgebied worden gecensureerd op basis van slecht beleid. Dat is een probleem", vindt Dad.
De toezichtraad staat niet alleen in de kritiek. Afgelopen week publiceerden Meta-medewerkers een open brief waarin ze het bedrijf verwijten dat het "islamitische en Palestijnse medewerkers en gebruikers censureert" en al jaren te weinig investeert om dat tegen te gaan.
Eerder sloot Meta het Facebook-account van de bekende Palestijnse fotojournalist Motaz Azaiza. Hij hoorde niet waarom. Nadat media erover berichtten, herstelde het bedrijf zijn account.
Meta reageerde niet op herhaaldelijke vragen van Nieuwsuur over het beperken van de zichtbaarheid van berichten over de Palestijnse gebieden. In een eerdere reactie op onderzoek van Human Rights Watch, dat gevallen van censuur documenteerde, liet het bedrijf weten dat het moderatiebeleid "ontworpen is om iedereen een stem te geven en tegelijkertijd onze platforms veilig te houden".
Lees meer over ons onderzoek in de verantwoording.
Dit artikel is onderdeel van de tweede aflevering van de Nieuwsuur-serie Ophef. In de eerste aflevering van de serie kijken we naar de onzichtbare invloed van kunstmatige intelligentie op verkiezingscampagnes. Beide afleveringen zijn te zien op NPO Start.
Nieuwsuur
Collectie
#Ophef
Buitenland
Deel artikel: