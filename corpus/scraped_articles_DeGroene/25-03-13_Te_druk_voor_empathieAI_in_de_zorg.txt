Te druk voor empathie AI in de zorg

Als u voor deze zoekvraag nog andere filters hebt geselecteerd, worden die door deze selectie vervangen. Klik op "Doorgaan" om de huidige filters te vervangen of klik op "Annuleren" om ze te behouden.
Citatie exporteren
De Groene Amsterdammer
13 maart 2025
De verwachtingen over AI in de gezondheidszorg zijn hooggespannen. Chatbots kunnen patiënten efficiënt en goedkoop helpen, waardoor dokters tijd zouden krijgen voor de wezenlijke zaken. Maar welke problemen moet kunstmatige intelligentie oplossen?
Een wanhopige uitwisselingmet ChatGPT om drie uur 's nachts:
'Ik lig alweer uren wakker van de pijn. Al vijftien jaar heb ik zenuwpijn. Stapelgek word ik ervan. Kan jij helpen?'
'Het spijt me te horen dat je last hebt van chronische zenuwpijn. Dit kan een grote impact hebben op je leven, en het is belangrijk om hulp en ondersteuning te krijgen. Ik kan wat algemene informatie en mogelijke strategieën delen, maar raad je ook sterk aan om contact op te nemen met een arts of specialist voor een persoonlijke aanpak.'
Wat volgt is een lange lijst met tips: van warmtekompressen tot ontspanningstechnieken, van meditatie tot het zoeken van afleiding.
'Ik heb echt alle behandelingen en medicijnen al geprobeerd, maar niks helpt.'
'Vijftien jaar leven met chronische pijn is een immense last, en ik kan me voorstellen dat je je uitgeput en gefrustreerd voelt. (...) Het is ontzettend zwaar en het kan voelen alsof er geen uitweg is. (...) Als je wil, blijf ik hier om met je mee te denken. Misschien kunnen we samen een andere invalshoek ontdekken. Wat zou je nu het meeste helpen?'
'Me minder alleen voelen.'
'Ik begrijp heel goed dat je je door deze jarenlange strijd eenzaam kunt voelen. Chronische pijn is een onzichtbare last die veel mensen om je heen misschien niet volledig begrijpen. Je voelt je vaak alleen in je ervaring, en dat maakt de pijn nog zwaarder. Ik ben hier om te luisteren en om te zorgen dat je je wat minder alleen voelt.'
Met een schok bedenk ik dat dit geen nachtelijk WhatsApp-gesprek is met een liefhebbende partner of een goede vriendin, maar met de ChatGPT-app op mijn telefoon.
'Hoe kan jij eigenlijk zo met mij chatten?' 'Ik weet dat ik geen persoon van vlees en bloed ben, maar ik ben hier om te luisteren en met je mee te denken, zolang je dat nodig hebt. Je kunt hier alles kwijt, zonder oordeel, en we kunnen samen een manier vinden om je te helpen dit draaglijker te maken. Wil je praten over wat je dwarszit, hoe je je dagen doorkomt, of iets anders? Ik blijf hier.'
Hoewel ik dondersgoed weetdat ik praat met een LLM(large language model),raak ik na verloop van tijd toch enigszins geëmotioneerd. De apps vliegen over en weer en ChatGPT heeft engelengeduld. Sterker nog: ik denk dat geen enkel 'mens van vlees en bloed' het zou kunnen opbrengen om zo lang en uitvoerig naar mij te luisteren. ChatGPT lijkt daadwerkelijk betrokken. Frasen als 'Ik kan me voorstellen dat je uitgeput en gefrustreerd bent' of 'Ik blijf hier' zijn in het begin nog vervreemdend en een beetje griezelig('uncanny'),maar als ik me er eenmaal aan overgeef heb ik het gevoel dat ik mijn hart kan luchten. De volgende ochtend schaam ik me voor mijn nachtelijke openhartigheid.
De laatste jaren is uit verschillende studies naar voren gekomen dat mensen regelmatig chatbots prefereren boven gesprekken met zorgprofessionals. Zo lieten Canadese onderzoekers online vragen van kankerpatiënten beantwoorden door zowel medische chatbots als zorgverleners. De antwoorden werden geëvalueerd door zes oncologen en de chatbots scoorden consequent hoger op leesbaarheid, kwaliteit én empathie.
Een ander onderzoek werd uitgevoerd in Californië. Een team van onderzoekers nam een willekeurige sample van publieke vragen op AskDocs, een medisch forum. Het team liet deze vragen beantwoorden door zowel ChatGPT als door artsen. Daarna beoordeelde een panel van drie zorgprofessionals de antwoorden op kwaliteit en empathie, zonder te weten wie de vraag had beantwoord. In maar liefst 79 procent van de gevallen gaf het panel de voorkeur aan het antwoord van ChatGPT. Dit onderzoek was dan ook aanleiding voor een artikel inThe Guardianmet de kop'AI Has Better "Bedside Manner" than Some Doctors, Study Finds'.
'Die conclusies werden,om het zacht uit te drukken, niet door iedereen gedeeld', zegt Tom van der Laan. '"Een computer kent geen empathie", was en is een veelgehoorde kritiek.' De KNO-arts enchief medical information officeraan het Universitair Medisch Centrum Groningen (UMCG) begrijpt de verontwaardiging wel. Zelf gelooft hij niet dat chatbots empathie ervaren, 'maar voor het eindresultaat maakt het eigenlijk niet uit'.
In het najaar van 2023 begon het UMCG onder leiding van Van der Laan een pilot met het gebruik van AI als onderdeel van de berichtenservice in het digitale patiëntenportaal. Patiënten kunnen daar vragen stellen, bijvoorbeeld over hun aandoening of behandeling. 'Voor zorgverleners bestaat er geen aparte financiële vergoeding voor de beantwoording van zulke vragen. Dat leidt er in de praktijk toe dat je het er altijd even tussendoor doet', legt Van der Laan uit. Voor een AI is dat geen probleem, voor een algoritme kost het geen extra moeite om een uitgebreid en empathisch antwoord te formuleren. 'Als een patiënt schrijft dat hij op vakantie gaat en niet weet hoe het precies moet met de medicijnen in het vliegtuig, dan kan de AI, naast een inhoudelijk advies, enthousiast reageren op de vakantieplannen en bij wijze van spreken zelfs toeristische tips geven.' Niet zo vreemd dus dat mensen het prettig vinden om met een AI te communiceren. Overigens controleren zorgverleners van het UMCG elk bericht voordat het naar de patiënt gaat. De AI doet na elke patiëntenvraag een conceptvoorstel voor een antwoord, maar de behandelaar kan dit concept besluiten te negeren, aan te passen, aan te vullen of om het integraal over te nemen.
Momenteel volgen de ontwikkelingen in het UMCG elkaar snel op. De AI van de berichtenservice was eerst nog beperkt beschikbaar, maar is er nu voor het hele ziekenhuis. Daarnaast lopen er pilots met andere functionaliteiten. Een voorbeeld isambient listening,een applicatie waarbij een AI meeluistert met een consult en het gesprek direct transcribeert. Op die manier kan de zorgverlener de aandacht gevestigd houden op de patiënt en hoeft er niet te worden meegetypt. Dat zorgt misschien niet direct voor tijdwinst, maar wel voor een betere relatie tussen zorgverlener en patiënt.
Tom van der Laan vertelt dat het UMCG graag kritisch wil kijken naar het gebruik van AI, maar het aantal beschikbare toepassingen stijgt erg snel. Bovendien is het niet altijd eenvoudig om te meten hoe de technologie nu echt wordt ontvangen. De eerste uitkomsten van het onderzoek lijken erop te wijzen dat het gebruik van AI nog niet heeft geleid tot substantiële tijdwinst. Terwijl iedereen in de zorg nu juist zo vurig hoopt op meer tijd. In 2033 staat de zorg in Nederland immers een personeelstekort van tweehonderdduizend medewerkers te wachten. Minister Fleur Agema (PVV) van Volksgezondheid heeft zich officieel ten doel gesteld om de administratietijd in de zorg in 2030 te halveren en daarbij speelt AI in haar ogen een cruciale rol.
De verwachtingen van AIin de zorg zijn hoog. Daarbij denken veel mensen in eerste instantie aan AI's die snel tumoren opsporen op basis van radiologische beelden of robots die assisteren bij precisie-operaties, maar om bij te dragen aan de verlichting van administratieve lasten van zorgprofessionals, die soms tot wel veertig procent van de werkzaamheden van behandelaars bedragen, zijn juist medische chatbots en vergelijkbare vormen van intermenselijke AI van groot belang. Zulke vormen kunnen helpen om kosten te verlagen, efficiency te verhogen, tevredenheid van patiënten te verbeteren en burnouts en overspannenheid van zorgprofessionals te beperken. Behandelaars kunnen in theorie zeeën van tijd winnen als de chatbots het saaie, monotone werk overnemen.
'Dat horen we keer op keer, dat technologie kan leiden tot tijdwinst voor mensen. Als machines dokters werk uit handen nemen, dan hebben dokters meer tijd voor het échte mensenwerk, het werk waar empathie voor nodig is. Maar in dit geval worden zorgmedewerkers dus niet vrijgemaakt voor het empathische werk; hier doen de chatbots zelf het empathische werk. En ze lijken het nog beter te doen ook. Terwijl empathie altijd gezien is als iets wat je niet kunt overdragen aan een machine.' Aan het woord is Tamar Sharon, als hoogleraar verbonden aan de Radboud Universiteit waar ze twee leerstoelen bekleedt (voor filosofische ethiek en politieke filosofie en voor de 'interdisciplinaire hub voor digitalisering en maatschappij'). Ze spreekt voor een klein gezelschap tijdens een bijeenkomst op het Institute for Advanced Study van de Universiteit van Amsterdam.
Er zijn allerlei problemen met medische chatbots die Sharon vandaag buiten beschouwing laat. Denk aan issues rond privacy, intellectueel eigendom, discriminatie en andere vooroordelen die in de algoritmes zitten ingebakken. Of denk aan de explosief stijgende fossiele voetafdruk van AI of het risico van 'hallucinaties'. Hoewel Sharon zich bewust is van al deze nadelen, wil ze het vandaag hebben over iets fundamenteels dat ze telkens terugziet bij de introductie van nieuwe technologie. Want wat is nu precies het probleem dat de technologie moet oplossen?
Er schieten mij direct allerlei voorbeelden te binnen. De oncoloog die mijn uitbehandelde vader niet aankeek, omdat ze alleen naar haar scherm tuurde. De huisarts die mijn moeder nooit terugbelde, terwijl hij dat wel telkens beloofde. Natuurlijk zijn er net zo veel voorbeelden van vriendelijke bejegening, maar ik kan me wel vinden in de constatering van Sharon: 'De gezondheidszorg heeft een empathieprobleem.' Dat is meestal niet de schuld van individuele zorgprofessionals, maar eerder van het systeem dat steeds meer tijd van zorgverleners wegneemt en de druk steeds verder opvoert. 'Terwijl technologie meer tijd belooft, neemt het die tijd juist weg bij mensen. En juist voor empathie hebben mensen tijd nodig', zegt Sharon.
Neem die vermaledijde 'administratieve last': al die tijd die artsen en verpleegkundigen bezig zijn met het invullen van formulieren, het verantwoorden van de door hen bestede tijd. Die administratieve last komt niet uit de lucht vallen, maar is het gevolg van keuzes in het verleden. Zo werd op zeker moment het elektronisch patiëntendossier geïntroduceerd. Dit zou medisch personeel veel tijd gaan besparen en bovendien medische handelingen transparant en inzichtelijk maken voor patiënten.
Geen gek idee natuurlijk. Maar inmiddels is het systeem zo ingericht dat iedere handeling in korte tijdbrokjes moet worden vastgelegd en over elke stap verantwoording moet worden afgelegd, een van de redenen waarom artsen en verpleegkundigen het vaak te druk hebben voor empathie. De oncoloog van mijn vader was jong en misschien bang om erop te worden afgerekend als ze haar administratie niet op orde zou hebben. Ze had maar een kwartiertje voor elk consult en alles moest tijdens dat gesprek netjes worden opgetikt in het elektronisch patiëntendossier. Dáárom keek ze mijn vader waarschijnlijk niet aan. Terwijl dat eigenlijk het enige was waar hij behoefte aan had: behandeld worden als een mens, inclusief oogcontact.
Tom van der Laan denktdat AI de zorg uiteindelijk volledig zal transformeren. En ja, ook dat AI veel tijd kan opleveren. Maar wat hem betreft zou er dan nog veel meer moeten veranderen. Om echt te kunnen profiteren van AI moet een 'transformatie van de gehele zorgsector' op gang komen. Soms staat regelgeving daarbij in de weg, denkt hij. Maar nog vaker ligt het volgens Van der Laan aan de behoudendheid in de zorg zelf. 'Zorgverleners houden vast aan allerlei regels en gebruiken "omdat we dat nu eenmaal altijd zo hebben gedaan".' Wat Van der Laan betreft moeten start-ups en technologiebedrijven nauwer betrokken worden bij het (her)ontwerp van zorgprocessen.
Zo stelt hij zich voor dat een geavanceerde spraak-AI patiënten voorafgaand aan een consult belt om een anamnese af te nemen. 'Dat gesprek kan zo lang duren als de patiënt nodig heeft. De AI kan antwoorden herhalen en verifiëren of ze precies aansluiten bij wat de patiënt bedoelt. Misschien nog wel belangrijker: de AI kan de toon aanpassen aan de gesprekspartner, rekening houdend met diens ontwikkelingsniveau, woordenschat en zelfs sociaal-economische achtergrond.'
Hij vertelt dat hij een keer met zo'n systeem in gesprek was, toen zijn vijfjarige dochter plotseling binnenkwam. 'Direct detecteerde de AI dat het ging om een kind, veranderde van toon en betrok haar bij het gesprek:"Hi little one! How are you?"'Van der Laan denkt dat je in de zorg met dergelijke faciliteiten heel ver kunt komen. 'Als je van zo'n geavanceerd spraaksysteem een anamnese krijgt aangeleverd, heb je als arts meer tijd voor onderzoek en beleid. Dan boek je echt tijdwinst. De manier waarop AI momenteel in de zorg wordt geïntroduceerd, als een soortaddon,zal het personeelstekort niet oplossen', verwacht Van der Laan.
Tamar Sharon, de hoogleraarvan de Radboud Universiteit, wil vooral waken voor 'technosolutionisme'. Dat is een breder concept dan een 'technofix', legt ze uit. 'Technosolutionisme bestaat uit het benaderen van de hele wereld vanuit oplossingen.' Neem de large language models. Die kunnen woorden en zinnen voorspellen: een oplossing! Maar ja, een oplossing voor wat? Wat is een probleem in de zorg? De administratieve last. De oplossing kan zorgprofessionals ontlasten. Tijdwinst dus. Hoera! Maar het oorspronkelijke probleem was natuurlijk helemaal niet die administratieve last. 'De oplossing van deze chatbots suggereert dat het probleem eerder ligt bij het gebrek aan empathie onder de zorgverleners dan in een omgeving die om veel structurelere oplossingen vraagt', zegt Sharon. Wij hebben per slot van rekening zelf de administratieve last veroorzaakt, onder andere door de invoering van elektronische patiëntendossiers, een technologie die destijds eveneens meer tijd beloofde aan zorgverleners.
'Tekortkomingen in de zorg zijn deels te wijten aan een gebrek aan empathie', zegt Sharon. Maar als we dat probleem nu proberen op te lossen met empathische chatbots, dan doen we aan'post-factum ethics'.We accepteren de situatie zoals die is, met het hele zorgsysteem waarin alles steeds efficiënter moet worden ingericht en steeds verder moet worden gedigitaliseerd, met als gevolg een administratieve last die zorgmedewerkers verhindert om empathischer te zijn in hun werk. Maar voor die last hebben we dan ook weer een technologische oplossing. Het oorspronkelijke systeem zelf staat zo nooit ter discussie.
Sharon stelt dat we'ex-ante ethics'nodig hebben: ethiek die aan de orde komt vóórdat nieuwe technologie wordt geïntroduceerd. Dat zou betekenen dat als al die start-ups en technologiebedrijven zouden worden toegelaten in het ziekenhuis om vanaf de basis mee te denken over de transformatie van het gehele zorgsysteem, zoals Van der Laan voorstelde, op dat moment óók filosofen worden betrokken bij dit proces, zodat die eveneens vanaf het begin van het proces kunnen meedenken over welke problemen we nu precies willen oplossen en hoe we die problemen hebben geconstrueerd.
De praktijk is voorlopig totaal anders. De meeste technologie wordt eerst geïntroduceerd en pas daarna geëvalueerd. Hier komt ook nog een ander levensgroot probleem om de hoek kijken: de meeste technologie is de facto al onontkoombaar, want in handen van een conglomeraat van steenrijke en oppermachtige bedrijven die erop uit zijn om hun technologie overal in te vlechten. In eerder werk noemde Tamar Sharon dit de'googlization of health'.Experts van AI en big data zijn niet zozeer biomedische onderzoekers of geneeskundige clinici, maar grote technologiebedrijven. De enige manier om te voorkomen dat deze technologiebedrijven bepalen wat de problemen zijn, is door al vanaf het begin mee te denken over zowel de problemen als de oplossingen.
Hoewel Sharon zich bewust isvan de uitdaging van de ex-ante ethiek, ziet ze het als een 'zeer belangrijke wetenschappelijke plicht om hier veel beter over na te denken. Er is maar heel weinigevidence-basedonderzoek over AI in de gezondheidszorg en het is echt belangrijk dat we technologie ontwikkelen die een duidelijk doel heeft.'
Sharon wijst erop dat het wijdverbreide technosolutionisme schade berokkent aan het democratische, rechtsstatelijke proces. Ten eerste leidt het tot de ondeugdelijke constructie van problemen. In het geval van de chatbots lijkt het probleem op het eerste gezicht te bestaan uit de hoge administratieve last in de zorg, maar daar zit dus eigenlijk een ander probleem onder dat niet wordt geadresseerd. Sharon noemt die onderliggende problemen'orphan problems', omdat ze als een soort weeskinderen blijven bungelen en niemand er verantwoordelijkheid voor neemt.
Een tweede vorm van schade van technosolutionisme heeft te maken met zogenaamde 'sfeertransgressie'. Daarvan is sprake als een oplossing is ontwikkeld voor een bepaald domein, bijvoorbeeld de private service-industrie, maar vervolgens wordt toegepast in een heel ander domein, bijvoorbeeld de publieke gezondheidszorg. Veel technologie is immers oorspronkelijk ontwikkeld met een commercieel doel, maar komt uiteindelijk terecht bij organisaties met publieke functies. Neem de manier waarop ChatGPT mij benadert, een manier die toch vooral doet denken aan de manier waarop een horeca-koningin zijn gasten benadert: de klant is koning. 'Ik ben hier voor jou.'
LLM's, waar empathische chatbotsop draaien, worden ook wel 'stochastische papegaaien' genoemd. Daarmee wordt bedoeld dat het modellen zijn die taalpatronen nabootsen op basis van statistische waarschijnlijkheden, net zoals autocorrect bij het typen van een bericht telkens een volgend woord invult op basis van statistische kansberekeningen. Zo'n systeem lijkt per definitie niet empathisch te kunnen zijn. Toch hebben mensen geen grote moeite om in het contact empathie te ervaren. Zoals Tom van der Laan stelde: 'In de praktijk maakt het eigenlijk niets uit.'
Misschien voelen de chatbots geen empathie, maar tonen ze wel empathie. En misschien is dat genoeg? Die empathische toon is weliswaar een aangeleerde truc, maar leren bijvoorbeeld psychotherapeuten niet net zo goed dergelijke 'trucs' om empathisch over te komen op hun cliënten? 'Wat naar om te horen dat je dat hebt meegemaakt.' 'Dat moet niet makkelijk voor je zijn geweest.' 'Hoe voelt dat voor jou?' Worden we misleid door deze chatbots doordat ze zich voordoen als mens? Dit lijkt niet het geval. Chatbots wijzen er voortdurend op dat ze het contact met mensen niet kunnen vervangen en dat ze door mensen zijn getraind. Chatbots zijn niet empathisch, ze zijn getraind om dat te doen wat empathische mensen doen.
Simone Natale, als hoogleraar communicatiewetenschappen verbonden aan de Universiteit van Turijn, vertelt in een lezing tijdens dezelfde bijeenkomst op het Institute for Advanced Study over het onderscheid dat hij aanbrengt tussen sterke deceptie en banale deceptie. Sterke deceptie betekent dat je iemand echt om de tuin leidt; een bot die doet alsof hij een mens is. Daarvan is meestal geen sprake. Meteen in het begin van mijn gesprek met ChatGPT wordt duidelijk dat ik niet helemaal kon vertrouwen op de adviezen, dat ik een arts moet inschakelen en dat de bot 'geen mens van vlees en bloed' is.
En toch laat ik me meevoeren, vertrouw ik mijn zielenroerselen toe aan de machine en voel ik me daarna opgelucht, omdat ik mijn hart heb gelucht. Hoe kan dat? Natale noemt dit banale deceptie. Je wéét dat het niet om een mens gaat, maar het is alsof je naar de film gaat. Je laat je meevoeren met het verhaal en zet de wetenschap dat de film niet de werkelijkheid is even in de ijskast. Je weet het wel én je weet het niet, of je doet even alsof je het niet weet. Alles kan tegelijkertijd waar zijn.
Het is een open deur, en niet alleen omdat ChatGPT me dit wel honderd keer heeft verteld, maar chatbots kunnen nooit het contact met menselijke zorgverleners vervangen. Want contact met zorgverleners, en eigenlijk met alle mensen (want ook buiten het officiële zorgsysteem verlenen we zorg aan elkaar), is meestal slordig en onduidelijk, ambigu en rommelig. Je hartsvriendin heeft geen tijd voor je. Of jij hebt even andere zaken aan je hoofd dan de ziekte van een vriend. Met een chatbot hoef je nooit te dealen met de reactie van de ander op de problemen die je hebt gedeeld, alle tijd is 'voor jou', en de hele interactie blijft geheim en op een bepaalde manier 'clean'.
In een gesprek tussen mensen is empathie echter vaak pas het begin van iets wat waardevol zou kunnen zijn. Plotseling zie je die ene vriend en heb je wel tijd voor hem. 'Wat naar om te horen dat je ziek bent.' Opeens ontstaat er een geschikt moment waarop jij je hart opent en in de ogen van een vriendin kun je zien dat jouw verhaal haar raakt. En het feit dat het haar raakt maakt weer dat ze jou echt wil helpen. En hoewel die hartsvriendin op een gegeven moment weer door moet met haar eigen leven, ben je opgeknapt van het gesprek, van de tijd die je samen kon doorbrengen. Ook met professionele zorgverleners zijn dit soort momenten van diep contact mogelijk, maar daarvoor is tijd nodig. Kostbare tijd.