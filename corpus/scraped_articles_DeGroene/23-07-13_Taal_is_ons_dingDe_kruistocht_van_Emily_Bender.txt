Taal is ons ding De kruistocht van Emily Bender

Als u voor deze zoekvraag nog andere filters hebt geselecteerd, worden die door deze selectie vervangen. Klik op "Doorgaan" om de huidige filters te vervangen of klik op "Annuleren" om ze te behouden.
Citatie exporteren
De Groene Amsterdammer
13 juli 2023
We laten ons te snel imponeren door technologie die menselijke intenties nabootst, zegt computerlinguïst Emily Bender. Wat weet een computer nou over de diepte van onze 'hm' of over een al dan niet instemmende 'ja'?
Iedereen doet het.Binnen minder dan een week tijd hoor ik het van de dochter van de vriendin die haar sociologie-scriptie schrijft over institutioneel vertrouwen; van de vriend die een bruidspaar moet toespreken, waarvan hij uit Nederland en zij uit Roemenië afkomstig is; van de neef die een gedicht wil insturen voor De Gedichtenwedstrijd. Bij dat laatste blijf ik even hangen, terwijl het me niet boeit. Zozeer níet dat het ook weer verdacht is. Ben ik bang voor techniek? Bang iets niet te begrijpen wat ik me niet kan veroorloven niet te begrijpen?
De neef dus, vrolijk aspirant dichter van beroep, al jaren trouw inzender van een gedicht voor wat voorheen Turing Gedichtenwedstrijd heette - een bijzondere competitie omdat zowel professionals als amateurs kunnen rekenen op anonieme beoordeling - tovert de mooiste poëzie op het computerscherm tevoorschijn dankzij zijn gerichte invoer. Hij staat er zelf ook van te kijken. Haiku, sonnet,you name it. Waar ik zelf vooral van sta te kijken is zijn enthousiasme. Is het de nieuwigheid? De onverwachte kick van het één-druk-op-de-knop-effect? Waarom zou je iets de wereld willen insturen als je het niet zelf hebt geschreven?
Omgekeerd: wat moet een jury met gedichten die niet uit een menselijk maar uit een computergestuurd brein afkomstig zijn? Een bruidspaar dat niet door een intimus maar door de vruchten van een taalprogramma wordt toegesproken? Docenten die de scripties van hun studenten op een ander soort plagiaat moeten toetsen? En om deze kwestie meteen maar even op wereldniveau te tillen: wat moeten burgers waar ter wereld ook die niet weten of de informatie die hen bestookt klopt?
Computerlinguïst Emily Bender(49), zelf ontwerpster van taalprogramma's, werkzaam aan de Universiteit van Washington, maakt zich zorgen over de gretigheid waarmee 'we' ons storten op de nieuwe mogelijkheden die de computer ons biedt op het gebied van taal, communicatie, tekstproductie. Taalprogramma's zijn systemen die erop gericht zijn om voorspellende taken uit te voeren, dus tekst te genereren op basis van de waarschijnlijkheid van een letter, woord of zinsnede. Aanvankelijk werden de programma's ingezet voor spraakherkenning, vertaling, classificatie van documenten. Inmiddels zijn de systemen zo opgewerkt dat gesprekken kunnen worden gesimuleerd en verwerkt zodat je met digitale apparaten kunt communiceren alsof je met een werkelijk persoon te maken hebt.
Willen we dit, vraagt Bender zich retorisch af, het verschil opheffen tussen iets wat menselijk is en iets wat voortkomt uit een computer? Alsjeblieft, zegt ze, vergeet niet dat woorden een betekenis hebben, en dat die betekenis afhankelijk is van de context. Haar basisidee ook bij computerlinguïstiek: taal is ervoor om mensen met elkaar te laten praten en wederzijds begrip te bereiken. Het gaat om interactie van mens tot mens.
En een chatbot is geen mens. Ze kan het niet vaak genoeg zeggen en schuift aan bij een lokale nieuwsshow op tv om nog maar eens te waarschuwen voor goedgelovigheid op tech-vlak. Als studenten denken hun essay te kunnen schrijven met behulp van een chatbot... Het kán ja, kennelijk, maar moet het ook? Wat is er aan de hand dat toekomstige wetenschappers zichzelf hiermee in feite bij voorbaat diskwalificeren, er kennelijk geen eer in scheppen zélf iets te bedenken en bovendien kritiekloos meegaan in een op vele fronten riskante technologische ontwikkeling?
In Benders beide oren bungelt een opvallend zilveren sieraad, dat bij nadere bestudering - ik zie de tv-opname via YouTube - de vorm van een octopus heeft. Misschien is ze gek op het dier sinds ze de Netflix-documentaireMy Octopus Teacherzag over de vriendschap tussen een filmmaker en een in de diepe wateren van Zuid-Afrika woonachtige octopus. In hetzelfde jaar dat die documentaire een hit was, 2020, schreef zij samen met een collega aan de universiteit een stuk over de beperkte reikwijdte van grote taalprogramma's, oftewel Large Language Models, en de technologie achter chatbots zoals het recente ChatGPT. De titel van het stuk: 'Op weg naar het begrijpen van natuurlijke taal. Over betekenis, vorm en begrip in het data-tijdperk.' Met behulp van een verhaal waarin een octopus de hoofdrol speelt, maakte ze haar stelling duidelijk. Hoe intelligent iets ook kan zijn, het komt niet in de buurt van een mens.
De situatie is als volgt: twee schipbreukelingen, ieder aangespoeld op een onbewoond eiland, maken dankbaar gebruik van de telegraafmogelijkheden die vorige bewoners hebben achtergelaten, en communiceren met elkaar via een kabelverbinding onder water. Drenkeling A en drenkeling B typen vrolijk over en weer boodschappen. Ondertussen ontdekt O, de hyperintelligente octopus die de eilanden kan bezoeken noch observeren, een manier om de kabel af te tappen en de gesprekken tussen A en B af te luisteren.
O weet helemaal niets van de Engelse taal maar kan wel goed regelmatig terugkerende patronen ontwaren. Gedurende de tijd leert O met grote precisie te voorspellen hoe B zal reageren op wat A zoal zegt. Al gauw breekt O in in het gesprek en doet zich voor als B die antwoord geeft aan A. Dit gaat een tijdje goed, en A gelooft dat O communiceert zoals zowel zij als B doen - met betekenis en bedoeling. Dan roept A op een dag uit: 'Ik word aangevallen door een kwaaie beer! Wat moet ik doen om me te verdedigen? Ik heb alleen wat stokken hier!' De octopus in de rol van B faalt jammerlijk. Hoe kan het anders? Hij heeft geen idee wat beren of stokken zijn. Kan niet op de gedachte komen, net zomin als ik overigens, dat A kokosnoten moet verzamelen, en met behulp van touw een katapult moet zien te maken. Arme schipbreukeling. En arme octopus, die ondanks zijn verbluffende skills toch tekortschiet.
Emily Bender zet graag dieren inom iets duidelijk te maken. Ze heeft thuis twee katten, Euclid en Euler, vernoemd naar respectievelijk de oud-Griekse wiskundige Euclides en de achttiende-eeuwse Zwitserse wiskundige Leonhard Euler. In het uitgebreide profiel dat dit voorjaar van haar verscheen inNew York Magazinewordt ze neergezet als een 'extravagante nerd'. Iemand die héél veel dingen weet en snapt, die slechts door vakgenoten helemaal gevolgd kan worden, maar die zich verantwoordelijk voelt voor de maatschappelijke effecten van de vorderingen op haar vakgebied. Die er niet voor terugschrikt haar kennis te populariseren voor het grotere publiek, omdat ze zich zorgen maakt. Vandaar die vergelijking van een Large Language Model met een octopus: goed in nabootsing maar slecht met feiten en echte kennis. Bovenal: geen idee hebbende van bedoeling en betekenis.
En dan is er nog de papegaai, zij het de stochastische variant. 'De mens is geenstochastic parrot',is een van haar bekendste uitspraken, oftewel: de mens is niet een papegaai die in voorspelbare patronen iets uitkrijt. In een wat recenter stuk nog, getiteldOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?(2021) legt ze dit, samen met drie coauteurs, extensief uit. Het is geen onderzoeksverslag maar een zeer academisch getoonzette risicoanalyse, met 158 literatuurverwijzingen. Bender en co slaan alarm over het kritiekloze enthousiasme waarmee techneuten, wetenschappers en consumenten de nieuwe taalkundige mogelijkheden op het gebied van kunstmatige intelligentie omarmen.
Toen dit stuk verscheen, werden twee van de vrouwelijke coauteurs paradoxaal genoeg ontslagen als mede-leidinggevende van Google's Ethical AI Team, terwijl ze aanvankelijk nog aan hun publicatieplicht leken te voldoen. Hoezo ethisch? De auteurs lieten het niet over hun kant gaan en zochten de publiciteit. Zeker naar academische maatstaven ging het stukviral,en de kwalificatie 'stochastic parrot' kwam met stip binnen in het grote tech-woordenboek.
Het activisme van Benderis herleidbaar tot maatschappelijke feiten, waarover straks meer, maar heeft ook een morele ondertoon. Ik weet niet of je dit humanisme moet noemen, maaroverallis in haar stukken en interviews een ontzetting te proeven over de techniek die op de loop lijkt te gaan met de mens en de mens die dat niet erg lijkt te vinden. Waarom degraderen we onszelf tot eenmachin,vraagt ze zich af, en ik twijfel of ik dat moet vertalen als apparaat of machine. Waarom denken we zo graag dat iets kunstmatigs net zo slim, zo niet slimmer kan zijn dan een mens?
Op zich een grappige verzuchting uit de mond van iemand die zelf zo'n twintig jaar geleden'just for fun'begon met het schrijven van taalprogramma's voor de computer. Al zou je ook kunnen zeggen dat ze dus weet waarover ze het heeft, en met recht angst kan voelen voor de kant die het uitgaat met artificiële intelligentie. Dat hele idee van intelligentie bevalt haar niet, wit en mannelijk gedomineerd als die volgens haar is. Het liefst zou ze, in navolging van een lid van het Italiaanse parlement, een alternatieve naam voor AI ingevoerd zien: 'Systematic Approaches to Learning Algorithms and Machine Inferences'. Zodat je meteen kunt zien waarmee we te dealen hebben: 'Is deze Salami wel zo intelligent?' 'Kan deze Salami een roman schrijven?' 'Verdient deze Salami mensenrechten?'
Op een of andere manier lijkt het feit dat een computerprogramma in staat is om betekenisvolle tekst te produceren juist voor sommige taalwetenschappers een totale demystificatie van de mens als natuurlijke taalgebruiker. Dat ik in de jaren tachtig vanuit de studie Nederlandse Taalen Letterkunde de afslag nam naar Algemene Taalwetenschap, had te maken met een hang naar een meer exacte tak van wetenschap en een ontzag voor wiskunde. Dat hele wonderbaarlijke gegeven dat er zoiets bestaat als t a a l, wereldwijd in alle mogelijke verschijningsvormen, dat kinderen het systeem binnen een paar jaar beheersen, dat mensen elkaar kunnen verstaan en zich met elkaar kunnen onderhouden, dat moet toch in regels en modellen geanalyseerd, verklaard en zelfs voorspeld kunnen worden. Eindelijk, echte wetenschap bedrijven.
Het 'hardste' onderdeel van de taalwetenschap was destijds de Transformationeel Generatieve Grammatica (TGG), een uitvinding van Noam Chomsky (1928) die toen nog doorging voor een hoogwaardig denker. Dat de mens in staat is om in een relatief kort tijdsbestek een taal te leren, moet ofwel betekenen dat er een aangeboren taalvermogen bestaat ofwel dat een taal een systeem is met een beperkt aantal regels dat een oneindige hoeveelheid uitingen kan produceren. Hoe mooi zou het zijn als die regels achterhaald zouden kunnen worden, en dat die dan meteen iets zeggen over het taalvermogen dat in ons dna schuilgaat.
Was daarvóór grammatica nog iets prescriptiefs, gebaseerd op voorschriften, regels en uitzonderingen, nu werd het ingezet om natuurlijke taal te beschrijven met behulp van formele, wiskundige inzichten. De gevestigde linguïstiek voelde zich erdoor aangevallen. De TGG van Chomsky had een revolutionair, democratisch aureool, of het is als zodanig in mijn geheugen beland dankzij de docent die mij ermee kennis deed maken, Hugo Brandt Corstius.
Gelukkig kon een oud-studiegenoot het me nog eens uitleggen wat we precies aan het doen waren. Chomsky was op de eerste plaats geïnteresseerd in de vorm van de taal. Hij maakte een onderscheid tussen de verschijningsvorm van de taaluiting, de oppervlaktestructuur, en een niet-waarneembare dieptestructuur. Om van het een bij het ander te komen ontwierp hij transformaties, veranderingsopdrachten die per taal konden verschillen. Zinnen werden schematisch weergegeven in boomstructuren, bij voorkeur binair, transformaties zorgden waar nodig voor veranderingen in die structuren.
Zie ik nu weer zo'n 'boom' op papier, met z'n vertakkingen, dan voel ik die in mijn buik. Wat wás dit voor iets magisch? Het was abstract, maar het was logisch. Hoe de woorden vanuit het taalsysteem aan hun betekenis kwamen bleef echter een raadsel. Daarvoor moest je dan toch weer te rade bij de softere afdelingen van taalwetenschap, bijvoorbeeld bij de taalfilosofie en de sociolinguïstiek. Rekenkunde en taalkunde bleven een studie lang in mijn hoofd om elkaar heen dansen. Ik studeerde af op zogehetenminimal responsesin gesprekken tussen docenten en studenten, en dacht iets te weten kunnen komen over gender verschillen in het gebruik van gespreksondersteunendehm's enja's door ze in een rekenkundig model te zetten (ik vat het even samen). Om erachter te komen dat de enehmde andere niet is, en dat de betekenis van zelfs de miniemste taaluiting afhankelijk is van de context. Ik denk dat een octopus het niet klaar zou spelen om op een relevante dan wel genderspecifieke manier tehm-en.
De oud-studiegenootdie me hielp m'n Chomsky weer op te frissen, vindt het maar gênant. Dat we onze jeugdige denkkracht (hij zegt: halve leven) besteedden aan iets wat uiteindelijk zo moeiteloos wordt ingehaald door effectieve algoritmen en snelle computerprogramma's. De grammatica is hoogstens een geheugendingetje geworden, een mnemotechnisch hulpmiddel om een andere taal te leren. De voor iedereen toegankelijke taalmodellen, ontworpen door OpenAI, zijn niet geïnteresseerd in regels voor grammaticaal correct taalgebruik, ze passen ze gewoon toe op basis van de meest voorkomende volgorde van woorden in een veelheid van semantische velden en produceren coherente, betekenisvolle teksten.
In dat 'betekenisvolle' schuilt volgens Emily Bender echter de crux. Ze geeft lezingen met titels alsResisting Dehumanization in the Age of AI,sluit haar tweets consequent af met #AIhype en is in die zin een geestverwant van filosofe Judith Butler. De grote taalmodellen zijn gereedschappen gemaakt door mensen die uit zijn op macht en geld, en reproduceren hun wereldbeeld. Butler ziet een gevaarlijk narcisme de overhand krijgen in de AI-droom, namelijk de drang te bewijzen dat wat we dachten dat onderscheidend menselijk was ook bereikt kan worden metmachins,en eigenlijk zelfs beter.
Het licht afstotelijke van Butler is dat ze er meteen ook maar het f-woord (niet de f van fuck maar de f van fascisme) ingooit, als ze beweert dat 'het doel' is de mens ervan te doordringen beter af te zijn mét AI dan zonder. De AI-droom wordt geregeerd door het verlangen naar perfectie; technologie neemt het over, weg van het menselijk lichaam. In de kenmerkende Butler-retoriek, voer voor kunstmatige imitatie: 'Wat leeft in mijn taal, mijn emotie, mijn liefde, mijn spraak, wordt verduisterd.'
Benders woorden zijn wat nuchterder. Haar mantra is: wees op je hoede, raak niet onder de indruk. Technologie creëren die je doet geloven met menselijke intenties te maken te hebben, vereist een stap terug, of opzij. We gedragen ons vanuit het idee dat dit een wereld is waarin sprekers de intentie hebben te zeggen wat ze zeggen, en ervan uitgaan dat wat ze zeggen iets betekent. Dit is wat filosoof Daniel Dennett 'de intentionele houding' noemt. Maar we hebben de wereld veranderd, aldus Bender. We maken apparaten die gedachteloos tekst kunnen produceren, en zijn niet opgehouden te denken dat ook achter die teksten een 'mind' zit, een menselijke bedoeling. Waarom worden we in die val gelokt met een chatbot die op ons lijkt? Zij volgt de gedachten van fulltime scepticus Dennett, die slimme apparaten wil maar geen kunstmatige collega's. We kunnen niet leven in een wereld met vervalste, nagemaakte mensen, amoreel bovendien. Niet in staat te sterven namelijk.
Hm.
Je zou je kunnen afvragen,vanuit een ander soort scepsis, in hoeverre een nieuwe generatie niet 'gewoon' is opgewassen tegen het technisch vernuft waarmee die wordt omringd. Goed weet te communiceren met en gebruik te maken van technische hulpmiddelen, en ondertussen weet heeft van het verschil met iets van vlees en bloed. En of nieuwe machinerie niet alleen maar gemakzucht in de hand werkt, maar juist weer een bijzondere menselijke intelligentie vereist om erin te stoppen wat eruit moet komen, en eruit te krijgen wat erin zit.
In dat laatste, wat erin zit, schuilt het overtuigendste aspect van Benders kruistocht. Haar zorgen over het per definitie 'gekleurde' arsenaal aan data waaruit wordt geput om bijvoorbeeld ChatGPT te voeden, werden onlangs nog bevestigd door een grootscheeps onderzoek in dit blad naar de websites achter Nederlandse AI-modellen. De racistische, seksistische en homofobe teksten en complottheorieën waarvan de meeste websites bol staan, krijgen via chatbots een oneindig en breed vertakt leven. Als de trainingsgegevens van een chatbot niet betrouwbaar zijn, leidt dat tot het verspreiden van vooroordelen, propaganda en verkeerde informatie zonder dat die informatie tot de oorspronkelijke bron te herleiden is.
Waarom maken we deze machines? vraagt Bender zich met fris gemoed af. Wie heeft er wat aan, behalve de grote bedrijven die elkaar beconcurreren om steeds maar groter te worden, meer macht uit te oefenen, de mensheid langzaam maar zeker te mindfucken en richting ondergang te dirigeren? De suggestie is altijd dat het handig is voor de mensen. Snel. Kostenbesparend. Er blijft tijd en geld over voor iets anders, wat dat andere ook moge zijn. Tuinieren? Gek worden?
Mocht het nog meer uit de hand lopen, met de mentale breekbaarheid van de gemiddelde 21ste-eeuwse mens, dan is de geestelijke gezondheidszorg daar in ieder geval dankzij de taalprogramma's wel op toegesneden. Meer mensen kunnen tegelijkertijd, zonder eindeloze wachtrijen, worden gediagnosticeerd met behulp van geautomatiseerde gespreksopnames en objectieve indicatoren van depressies of angststoornissen. Depressieve cliënten praten immers monotoner en zachter, en nemen meer pauzes. Angstige mensen praten sneller, ademen moeilijker.
Maar zijn die signalen betrouwbaar genoeg om een behandelplan in gang te zetten? 'Vrees niet!' roept Bender cynisch. 'AI kan alle details oppikken.' Dankzij technisch vernuft zouden dingen gehoord kunnen worden die het menselijk oor te boven gaan. Ook bij schizofrenie! Of als iemand aan een posttraumatisch stresssyndroom lijdt!
Afgezien van of het echt allemaal kan en werkt -'It makes me sad to see domain experts being drawn in this way',schrijft Bender - en die spraakopnames er zijn... wie kan er dan allemaal gebruik van maken, of liever gezegd: misbruik? We weten allemaal hoe het gaat met digitaal beschikbare informatie: die is er om verspreid te worden voor obscure doeleinden en nooit meer te verdwijnen. Ja.
De minimal response 'ja' heeft minstens twee betekenissen, zo weet ik sinds ik erop ben afgestudeerd: 'ik luister' en 'ik ben het met je eens'. Het hangt er helemaal vanaf wie er aan het woord is en waar diegene op uit is.
Het lijkt misschien ofEmily Bender een stap terug zou willen doen, of op z'n minst een pas op de plaats zou willen maken. Taalmodellen klein houden, in plaats van groot, groter, grootst te maken. In haar stochastische papegaaien-paper stipt ze echt nog een andere mogelijke uitweg aan: het dominante narratief doorbreken. Alert zijn op de schadelijkheid en eenzijdigheid van de data die worden ingevoerd. Oog hebben voor nieuwe sociale bewegingen met hun bijbehorende nieuwe documentatie.
Vooral vindt ze dat de mens moet ophouden zichzelf klein te maken: zo graag willen we geloven dat taalmodellen intelligent zijn dat we onze verwachtingen bijstellen aan wat de technologie ons biedt.
Dat het écht een mogelijk prijswinnend gedicht is dat uit de computer rolt, beter dan je zelf ooit zou kunnen schrijven.