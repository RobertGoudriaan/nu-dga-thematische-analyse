Het klopt niet, maar toch is het zo Onderzoek X en Meta dumpen de waarheid

Als u voor deze zoekvraag nog andere filters hebt geselecteerd, worden die door deze selectie vervangen. Klik op "Doorgaan" om de huidige filters te vervangen of klik op "Annuleren" om ze te behouden.
Citatie exporteren
De Groene Amsterdammer
6 februari 2025
Nu de trumpisten Musk en Zuckerberg desinformatie op hun socials niet meer actief bestrijden, moeten de gebruikers het onderling uitvechten. In dat gevecht werkt polarisatie ten faveure van de radicaal-rechtse minderheid.
De Algerijnse Imane Khelifwas bij haar geboorte een vrouw en identificeert zich nog steeds als zodanig. In 2024 nam de ervaren amateurbokser deel aan de Olympische Spelen, waar ze won van de Italiaanse Angela Carini. In tranen verklaarde die laatste dat ze het niet meer vol kon houden, en wel moest stoppen vanwege de pijn. En in no time begon men op sociale media te speculeren: Khelif zou 'eigenlijk' een man zijn, of intersekse, of een trans vrouw. Een paar jaar eerder zou een test afgenomen zijn waaruit zou blijken dat Khelif ongebruikelijk hoge testosteronspiegels had. Volgens de Russische baas van een door de Olympische Spelen verbannen testbureau zou ze zowel X-als de mannelijke Y-chromosomen hebben. De Italiaanse president Giorgia Meloni verklaarde: 'Atleten die genetisch mannelijke eigenschappen hebben, zouden niet mogen deelnemen aan de vrouwencompetitie.'
Niet dat er voor dit alles bewijs was. Khelif werd slachtoffer van een desinformatiecampagne; een die het bijzonder goed deed op X, voorheen Twitter. Op een persconferentie moest ze uiteindelijk benadrukken dat ze, echt, cisgender vrouw is. Het Internationaal Olympisch Comité noemde de ophef rond beide boksters het gevolg van een Russische lastercampagne en nam nadrukkelijk afstand van het verbale geweld en de discriminatie die Khelif moest ondergaan.
Deze campagne is niet uniek. Tegen de queergemeenschap vinden wel vaker zulke aanvallen plaats, vaak door mensen die denken dat ze aan de hand van foto's kunnen detecteren of iemand genderbevestigende zorg heeft gehad. Nepnieuws en bewerkte foto's zie je sowieso meestal rond gepolitiseerde thema's: het klimaat, oorlogen, racisme, corona.
Hoe ging X deze overduidelijkverzonnen informatie te lijf? Sinds 2023 heeft het bedrijf geen onafhankelijke factcheckers meer, maar gebruikt hetcommunity-opmerkingen ,een systeem waarbij gebruikers bij elkaar moeten aangeven of een bericht klopt, en vervolgens stemmen over het oordeel. Om bij de Olympische Spelen te blijven: die zomer plaatst een Nederlandse X-gebruiker een tweet waarin Khelif een 'transvrouw' wordt genoemd. Dat is evident onwaar en al snel wordt er een opmerking ingediend. Dan begint het stemmen. 38 gebruikers vinden de opmerking nuttig, negen vinden hem 'een beetje' nuttig en dertien bepalen: niet nuttig. Een duidelijke meerderheid wil dat de opmerking wordt geplaatst.
Toch komt er geen correctie. Het probleem is namelijk dat het systeem, dat is ingevoerd toen Elon Musk Twitter kocht en ontdeed van alle moderatie- en factchecking, gebruikers op basis van hun stemgedrag verdeelt over een politieke as van links naar rechts. Alleen als een aantekening door ongeveer evenveel gebruikers van de linkerzijde als de rechterzijde als nuttig wordt beschouwd, wordt het onder een post geplaatst: gebruikers moeten het dan eens worden. Van de ruime meerderheid die het originele bericht correct als nepnieuws aanmerkte is in die nieuwe verdeling weinig meer over. Het nepnieuws blijft zonder opmerkingen staan.
Zo'nwisdom of the crowds-systeem begint langzaam maar zeker de plaats in te nemen van traditionele factchecks. Ook Wikipedia werkt volgens een systeem van elkaar corrigerende gebruikers en Meta gaat er binnenkort mee aan de slag. De meerderheid van de notes verschijnt echter nooit omdat gebruikers het niet eens worden over de juistheid ervan. Daardoor hebben ze in de praktijk nauwelijks effect, blijkt uit onderzoek vanDe Groene Amsterdammer.
Via community-opmerkingen krijgt een radicaal-rechtse minderheid steeds meer grip op wat we als feiten beschouwen, blijkt uit onze data-analyse. We onderzochten de bijna negenduizend opmerkingen die sinds de introductie onder Nederlandstalige berichten op X zijn voorgesteld. Daarvan zijn er slechts 522 daadwerkelijk geplaatst, over de rest is ofwel te weinig gestemd, of er is tussen 'links' en 'rechts' geen overeenstemming gevonden, zoals bij het voorbeeld van Imane Khelif.
Veel community-opmerkingen verschijnen simpelweg niet door een gebrek aan stemmen. Maar bij een kwart van de misleidende berichten over lhbti+-ers worden correcties weggestemd door rechtse gebruikers. Linkse gebruikers doen dit ook, maar aanzienlijk minder vaak: in slechts drie procent van de gevallen.
Niet iedereen die gebruikmaakt van X mag community-opmerkingen plaatsen. Je moet je ervoor aanmelden en vervolgens moet je ongeveer een dag wachten voor je lid bent. In Nederland hebben ongeveer tweeduizend gebruikers ooit een opmerking ingediend, terwijl zo'n negentienduizend gebruikers er ooit een hebben beoordeeld. Uit onze analyse blijkt dat in Nederland minimaal zeven beoordelingen nodig zijn voordat een opmerking wordt geplaatst. Dat in Nederland relatief weinig community-opmerkingen verschijnen, lijkt deels te komen door een gebrek aan actieve vrijwilligers. Veertig procent van de opmerkingen wordt - ongeacht de stemmen - sowieso niet geplaatst omdat er te weinig beoordelingen zijn. Zeventien procent wordt door slechts één persoon of niemand beoordeeld.
In een filmpje op Facebook en Instagramkondigde Meta-baas Mark Zuckerberg deze maand aan dat hij ging stoppen met strenge moderatie rond thema's als gender en migratie, waardoor het bijvoorbeeld weer wordt toegestaan om het bestaan van trans personen te ontkennen en hen geestesziek te noemen. In hetzelfde bericht zei hij een einde te maken aan de inzet van externe factcheckers, en in plaats daarvan een op X geïnspireerd model te introduceren. Hij vergeleek het oude systeem met censuur, waarmee het voortaan afgelopen moest zijn. Vanaf nu wordt dus op de grootste sociale media door de gebruikers democratisch beslist of een bericht nepnieuws bevat. Dat, in combinatie met het feit dat Zuckerberg net als Musk een half jaar eerder expliciet zijn steun kenbaar maakte voor president Donald Trump, maakt dat tech - critici zich grote zorgen maken over de verspreiding van nepnieuws.
Meteen na de aankondiging van Zuckerberg riepen belangenorganisaties waaronder Bits of Freedom, PublicSpaces en Waag Futurelab op om grote platforms de rug toe te keren. Door te stoppen met factchecken en de moderatie drastisch te verminderen, zet het bedrijf volgens hen de deur open voor seksisme, homofobie, transfobie, racisme en andere vormen van discriminatie.
'Met deze stap treedt Meta in de voetsporen van X', schrijft de coalitie onder het initiatief #MakeSocialsSocialAgain. 'Sinds de overname van Twitter door Elon Musk is dit platform een broedplaats geworden voor desinformatie, haatspraak en politieke manipulatie. Niet eerder was de macht van Big Tech en hun eigenaren zo nauw verweven met politieke macht. Dit heeft grote gevolgen voor onze vrijheid in Europa en onze democratie.'
Polarisatie is het uitgangspunt van communityopmerkingen, en dat is een bewuste keuze. Toen het algoritme in 2022 werd ontwikkeld en geëvalueerd, was dat in de context van het Amerikaanse politieke systeem, met een scherpe tweedeling onder gebruikers aan beide uitersten van het politieke systeem. Het midden is in dat ontwerp nauwelijks vertegenwoordigd. Dat systeem wordt in Nederland ook toegepast, terwijl onze politiek heel anders in elkaar zit. Ook hier worden gebruikers onder twee polen verdeeld. En de scheidslijn ligt behoorlijk ver naar rechts, zo blijkt uit onze analyse. Alles ter linkerzijde van de VVD is 'links', alles ter rechterzijde van de VVD is 'rechts'.
'Linkse' gebruikers stemmen voor opmerkingen onder berichten van Raisa Blommestijn, rapper Kafka, Thierry Baudet en Caroline van der Plas; en 'tegen' notes bijRTL Nieuws,Frans Timmermans en Rob Jetten. Bij 'rechtse' gebruikers is dat andersom. Zij stemmen 'voor' opmerkingen bij posts van de mainstream media (NOS, RTL, NRC), Jesse Klaver, Frans Timmermans en Rob Jetten , en 'tegen' opmerkingen bij Raisa Blommestijn, Geert Wilders en Wierd Duk. Daarmee lijkt het systeem vooral een manier om je politieke opponenten aan te vallen.
Hoewel de opmerkingen van vrij hoge kwaliteit zijn, worden ze ook gebruikt om ruzies uit te vechten of om zelf nepnieuws te verspreiden. Onder een bericht van een verloofde vrouw , 'mijn eerste liefde wordt nu ook mijn eeuwige liefde! Ik heb ja gezegd!' , corrigeert iemand: 'Zo'n 40% van de huwelijken eindigd in een echtscheiding. Trouwen is geen garantie voor eeuwige liefde . '
Op 30 januari krijgen amateurmoderatoren een post te zien van GroenLinks-PvdA-Tweede
Kamerlid Luc Stultiens, die een screenshot deelt van de stemuitslagen over de btw-verhoging van 2,3 miljard in 2026. Stultiens schrijft: 'Op Twitter stoere praatjes, in de Tweede Kamer stemt de PVV gewoon voor gigantische verhogingen van de btw.' De voorgestelde communityopmerking is: 'Dit is nepnieuws verspreid door @groenlinks. Het plaatje is bewerkt en niet juist.'
Maar het plaatje is niet bewerkt - de community-opmerking is dus zélf incorrect. Komt er ondanks alles overeenstemming, dan vindt deze opmerking alsnog doorgang. Dat is overigens onwaarschijnlijk. In Nederland wordt 5,8 procent van de ingediende notes uiteindelijk bij het bericht gezet. De rest van de foutieve berichten blijft ongecorrigeerd staan.
Alexander Pleijter meldde zichmeteen aan toen hij zag dat X met community-opmerkingen ging werken. De universitair docent is coördinator van Nieuwscheckers, een factcheck-initiatief van de Universiteit Leiden. Het systeem heeft zeker potentie, denkt hij. Maar wat hem meteen opviel: 'Ik kreeg maar weinig Nederlandse berichten te zien, terwijl ik me daar wel voor had aangemeld. En bij de opmerkingen die überhaupt wat bijdragen duurt het veel te lang voor ze daadwerkelijk worden geplaatst. Na tien uur heeft een post op X zich allang verspreid, voordat er eindelijk een label onder komt te staan.' Uit onze analyse blijkt dat het gemiddeld tien uur en veertig minuten duurt.
Hoe kan het dat het systeem van X zoveel mankementen vertoont, terwijl Wikipedia al jaren heel goed draait op hetzelfde idee, namelijk het publiek inzetten om informatie te verzamelen én te beoordelen? 'Daar is het ook niet altijd makkelijk', zegt Pleijter. 'Ook op Wikipedia heb je onderwerpen die controversieel zijn en waarbij mensen moeilijk tot overeenstemming komen. Sommige lemma's gaan zelfs op slot omdat mensen voortdurend aan het sleutelen zijn. Op X heb je juist veel controversiële onderwerpen, die politiek beladen zijn.' Zo worden ook opmerkingen rond het coronavirus verdeeld over een links/rechts-as. Een correctie op het bericht dat het mRNA-vaccin je persoonlijkheid zou veranderen, wordt door enkele 'rechtse' stemmers als niet nuttig beoordeeld en daardoor niet geplaatst.
'Zoiets werkt pas goed als er zoals bij Wikipedia heel veel mensen aan meedoen', zegt Pleijter. 'Tussen de Nederlandse en de Engelstalige Wikipedia zie je een groot verschil . In het Nederlands zijn de pagina's minder actueel en uitgebreid, met meer fouten. Dat zie je ook terug op X. Je hebt nou eenmaal veel mensen nodig om crowdsourcing goed te laten werken.' Waar het bij tijdloze Wikipedia-artikelen geen ramp is als het even duurt voor er overeenstemming is, telt bij een bericht op X elke minuut.
Het systeem van community-opmerkingenmoet juist de politisering van feiten voorkomen. Het risico is dat dingen die evident niet kloppen of die geen politieke lading hebben wél gecorrigeerd worden, maar juist de meest gevoelige onderwerpen niet - zoals het klimaat of immigratie. Dat laatste blijkt ook uit onderzoek vanDe Groene.Over de onderwerpen waarbij feiten gevoelig liggen, wordt minder consensus bereikt. En die worden daardoor het minst vaak gecorrigeerd.
Uit onze analyse blijkt dat vooral opmerkingen over de oorlog in Gaza, racisme en discriminatie en lhbti+-kwesties het sterkst gepolariseerd zijn. Een community-opmerking wordt daarbij doorgaans óf massaal als 'nuttig' beoordeeld door linkse gebruikers, óf door rechtse gebruikers, maar zelden door beide groepen tegelijk. Wordt bij het thema 'Oekraïne-Rusland' - een minder gepolariseerd onderwerp in de Nederlandse politiek - zo'n acht procent van de ingediende community-opmerkingen geplaatst, bij 'lhbti+ en gender' ligt dat slechts op 2,8 procent.
Daarmee ondervinden vooral mensen uit minderheidsgroepen de lasten van een community-opmerkingensysteem. Veel desinformatie, zoals in het geval van Imane Khelif, blijft ongecorrigeerd rondzingen. Om de proef op de som te nemen analyseerden we alle berichten met een opmerking over het thema 'lhbti+ en gender' en vonden 54 posts met aantoonbaar feitelijke onjuistheden. Slechts twee daarvan kregen een opmerking, terwijl de overige 52 (96,2 procent) ongecorrigeerd bleven .
'Als je het systeem echt nuttig wil maken', zegt Pleijter, 'moet je een manier vinden waardoor de correcte opmerkingen daadwerkelijk worden geplaatst.' Een onafhankelijk bureau dat de community-opmerkingen checkt zou daarin juist een goede tussenoplossing zijn, denkt hij. Maar die onafhankelijke checkers zijn juist net geschrapt.
Afgelopen zomer klaagdeMark Zuckerberg dat de regering - Biden zijn bedrijf onder druk had gezet om tijdens de coronapandemie berichten rond het virus te verwijderen. 'In 2021 oefenden hoge functionarissen van de regering-Biden, ook vanuit het Witte Huis, maandenlang herhaaldelijk druk uit op onze teams om bepaalde covid-19-content te censureren, waaronder humor en satire', schreef hij in een brief aan een commissie van het Huis van Afgevaardigden.
Aan zulke strenge regels maakt hij nu definitief een einde, tot vreugde van vooral de rechterkant van het politieke spectrum. Desinformatie speelt niet symmetrisch aan beide kanten, concludeerde onder meer een recente studie inNature. In 2020 hadden gebruikers aan de rechterzijde weliswaar een grotere kans om van Twitter verbannen te worden, maar zij waren ook verantwoordelijk voor een aanzienlijk groter aandeel in de verspreiding van desinformatie. Omdat radicaal - rechts een van de twee polen in het algoritme vormt, krijgt juist deze groep de facto een veto om onwelgevallige opmerkingen tegen te houden.
Het oude systeem van Meta en Twitter was weliswaar strenger en onder die regels was de vrijheid van meningsuiting beperkter, zegt Alexander Pleijter. 'Maar alleen als je een heel brede opvatting hebt van de vrijheid van meningsuiting: dat je alles moet kunnen zeggen wat je wil en de meest absurde complottheorieën mag rondbazuinen en bevolkingsgroepen mag discrimineren. Ik denk dat je dat niet moet willen in een gezonde samenleving.'
De berichten die het meest beschadigend kunnen zijn, die sensationeel zijn, haatdragend , dat zijn de berichten die zorgen voor reacties, boosheid, commentaren. Pleijter: 'Dat soort berichten worden op sociale media daardoorjuistgepusht. Die krijgen via algoritmes een veel bredere verspreiding dan factchecks of beschaafde berichten. De sensationele berichten, daarop gaan mensen los. En daar enige rem op zetten, dat is natuurlijk geen inbreuk op de vrijheid van meningsuiting. Dat heeft met beschaving te maken.'
Veel communityopmerkingen verschijnen simpelweg niet door een gebrek aan stemmen