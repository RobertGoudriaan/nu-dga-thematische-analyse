Het opgelegde mensbeeld Essay Technologische beheersdrang beperkt ons

Als u voor deze zoekvraag nog andere filters hebt geselecteerd, worden die door deze selectie vervangen. Klik op "Doorgaan" om de huidige filters te vervangen of klik op "Annuleren" om ze te behouden.
Citatie exporteren
De Groene Amsterdammer
1 december 2022
De mens zoekt steeds vaker naar datagedreven oplossingen: al onze gegevens worden inmiddels opgeslorpt door Big Tech. Is het langzamerhand niet tijd om onze verhouding tot technologie eens grondig te herzien?
De Rabobank gaat betaaltransactiesaan CO2-uitstoot koppelen. Samen met fintechplatform Ecolytiq ontwikkelen ze een app die kan laten zien waar klanten betaald hebben en hoeveel CO2 ze daarmee uitstootten. Om de inschattingen preciezer te maken, wordt klanten gevraagd hoeveel vlees ze eten en of hun huis goed geïsoleerd is.
Ook het Italiaanse Bologna en het Duitse Beieren moeten eraan geloven. Daar krijgen de inwoners binnenkort een'smart citizen wallet':als je je afval scheidt, energie bespaart en het openbaar vervoer gebruikt, krijg je punten waarmee je bepaalde voordelen kunt krijgen, bijvoorbeeld korting op een publieke voorziening.
De beheersdroom dat we met technologie de wereld volledig stuurbaar kunnen maken begint steeds ingrijpender vormen aan te nemen. Aldous Huxley schreef in 1932 de dystopische romanBrave New World,over een genetisch gemanipuleerde toekomst waar de mensheid dankzij technologie een volledig pijnloos, maar ook betekenisloos bestaan leidt.Brave New Climatezou een passende opvolger kunnen zijn: over een algoritmisch gemanipuleerde toekomst waar bij je geboorte algoritmisch wordt berekend hoe oud je mag worden op basis van beschikbare grondstoffen en planetaire CO2-uitstoot. Omringd door pandemieën, klimaatrampen en oorlogen grijpen we steeds hardnekkiger naar algoritmische calculaties en datagedreven oplossingen.
Sinds corona zijn we de algoritmische logica almaar dieper in onszelf en onze samenleving gaan internaliseren. Zo gaat de Europese Commissie de digitale coronapas uitbreiden naar een digitale identiteit met al je persoonsgegevens waar op langere termijn ook biometrische gegevens uit gezichtsherkenningssystemen, vingerafdrukken en gegevens over opleiding, banengeschiedenis en sociale-mediagedrag aan gekoppeld kunnen worden. Een ander ingrijpend systeem is de 'Intelligent Speed Assistant' die sinds 6 juli in alle nieuwe auto's zit om snelheidsovertredingen, slaperigheid en smartphonegebruik te monitoren en 'afwijkend rijgedrag' te rapporteren wanneer de politie daarom vraagt. En dan is er nog het nieuwe register dat de Europese Commissie wil invoeren om alle bezittingen en transacties van burgers te registreren. Het gaat dan niet alleen om onroerend goed, grond en aandelen, maar ook cryptovaluta, sieraden, kunstwerken, auto's en boten. Het register zou nodig zijn om belastingfraude te voorkomen.
Handig voor toezichthouders en banken, maar gevaarlijk voor politiek onwelgevallige burgers, journalisten en klokkenluiders. Het geeft overheden meer inzicht in hun vermogen, boven op de informatie die ze al verzamelen, waardoor zij nog meer controle kunnen uitoefenen. De toeslagenaffaire en het door de rechter verboden Systeem Risico Indicatie hebben laten zien dat niet alleen criminelen en fraudeurs, maar ook onschuldige burgers hiervoor op hun hoede moeten zijn.
De heersende gedachtegang is dat deze ingrijpende systemen ons van bovenaf worden opgedrongen. Ze zouden het resultaat zijn van technocratische overheden en datahongerige techbedrijven die de samenleving voorspelbaar, stuurbaar, veilig en economisch winstgevend willen maken. Technocratische beheersdrift en commerciële datahonger spelen inderdaad een grote rol, maar verklaren niet waarom we deze weg zijn ingeslagen en waarom we dat blijven doen. Als we een andere weg willen inslaan en willen voorkomen dat de mens verdwijnt in een almaar uitdijend technologisch systeem, moeten we dieper graven en beginnen bij de relatie die wij met technologie zijn aangegaan.
De beheersdrift waarlangs corona-QR-bewijzen, digitale identiteiten en Intelligent Speed Assistants hun weg vinden, heeft een oorsprong in het beeld dat de mens van zichzelf heeft, het technologie-ontwerp dat daaruit voortvloeit, en het onvermogen om dat mensbeeld flexibel te blijven bijstellen. De Oostenrijkse filosoof Ivan Illich schreef in de jaren zeventig over onze relatie met technologie: 'De hedendaagse mens probeert de wereld naar zijn beeld te creëren, een volledig door mensen gemaakte omgeving te bouwen, en ontdekt vervolgens dat hij dat alleen kan op de voorwaarde dat hij zichzelf voortdurend opnieuw aanpast om erin te passen.'
Kortom: we doen er alles aan om onszelf en onze technologische omgeving aan de mal van ons eigen mensbeeld aan te passen. In plaats van een actieve onderhandeling met ons mensbeeld aan te gaan en onze technologische omgeving grondig te herzien, kiezen we er liever voor om het beeld dat we van onszelf hebben te bestendigen door middel van aanpassing aan onze technologische omgeving.
Als we de wereld zoals Illich beschrijftmet technologie naar ons eigen beeld vormgeven, moeten we bevragen welk beeld die'contemporary man'dan tegenwoordig van zichzelf heeft en welke gevolgen dat heeft. In haar boekThe Age of Surveillance Capitalism(2019) geeft Harvardhoogleraar Shoshana Zuboff daar een antwoord op. Aan de hand van historische bronnen, patentaanvragen en interviews laat ze zien hoe mede onder invloed van Silicon Valley een behavioristisch verklaringsmodel voor gedrag dominanter is geworden. In dat model is de mens niets meer dan een stimulus-respons-machine die weerloos is overgeleverd aan de notificaties, rode bolletjes en YouTube-rabbit holesvan Big Tech. Wij reageren immers - zie breindeterminist Dick Swaab - volgens miljoenen jaren oude, door de evolutie gevormde psychologische mechanismen en zijn slaven van ons reptielenbrein.
Het gevaar van deze manier van denken is niet alleen dat het onwaar is, maar dat het waarheid kan worden omdat we (zoals Illich beschrijft) onszelf, onze omgeving en onze technologische systemen aan dit beeld aanpassen. Hoe wij denken dat de mens psychologisch in elkaar zit, bepaalt ons technologie-ontwerp, en dat bepaalt op zijn beurt weer onze psychologie en ons denken. Zo is de mantra dat wij slechts marionetten zijn van een handjevol techbedrijven omdat zij ons met de door hun verzamelde data 'beter kennen dan we onszelf kennen' vrijwel gemeengoed geworden. En nu heeft Big Tech inderdaad miljoenen datapunten waarmee zij voorspellingen doen over ons gedrag. Maar als die voorspellingen kloppen, dan komt dat niet doordat deze bedrijven ons ten diepste kennen, maar doordat ze bij voorbaat onze keuzes en klikopties bepalen waardoor onze onvoorspelbaarheid afneemt.
Het gevaar van grote techbedrijven is dan ook niet dat ze ons te goed kennen, maar juist dat ze onsnietkennen en claimen onswelte kennen op basis van onze data.
Met het 'reptielenbrein' als verklaringsmodel hebben we onszelf afhankelijk verklaard van de techindustrie: techbedrijven hebben immers een probleem gecreëerd dat alleen zij met een 'humaner' ontwerp van hun technologie kunnen oplossen, omdat wij nu eenmaal weerloos zijn overgeleverd aan de gedragsmanipulaties die zij in hun ontwerp hebben aangebracht. Zo timmeren reeds nieuwe techbedrijven aan de weg die 'humane' waarden zoals'kindness'als ontwerpuitgangspunt nemen. Dat klinkt nobel, maar het betekent dat de techindustrie een groot deel van de macht in handen heeft om te kunnen definiëren wat wij onder 'humaan' en 'inhumaan' moeten verstaan. En dat niet alleen. Ze hebben ook een groot deel van de macht in handen om te kunnen definiëren wat intelligentie betekent. Het soort brein waar wij slaaf van zouden zijn is namelijk niet zomaar een brein. Het is een verouderd brein: een stukje 'verouderde hardware' waarmee we het altijd zullen afleggen tegen de 'supercomputers' uit Silicon Valley, zo wordt ons uitgelegd door kunstmatige-intelligentie-evangelisten als Ray Kurzweil en Yuval Noah Harari.
Met deze AI-propaganda heeft de mens zichzelf vastgedraaid in een gevaarlijke cirkelredenering: 1) wij zijn ons brein; 2) ons brein is een computer; 3) Silicon Valley maakt betere computers; 4) de 'humane' techindustrie maakt betere computers.
Pas als we deze cirkelredenering kunnen doorbreken, ontstaat ruimte voor een interactievere relatie met technologie. Dan kunnen we ons losmaken van het mensbeeld dat het uitbuitende verdienmodel achter onze digitale wereld blijft faciliteren. Om de eerste stap onderuit te halen kunnen we wellicht terecht bij de Amerikaanse neurowetenschapper Alva Noë. In zijn boekWij zijn toch geen brein?(2012) schrijft hij dat wij meer zijn dan ons brein omdat bewustzijn en persoonlijkheid niet in onze hersenen zitten. Bewustzijn is iets wat we doen in dynamische interactie met de wereld om ons heen: om het leven te kunnen ervaren, zijn we afhankelijk van de samenwerking tussen hersenen, lichaam en een betekenisvolle omgeving. Zonder deze verknoping kunnen we de wereld niet bewust ervaren.
Voor de tweede bewering, 'ons brein is een computer', moeten we kijken naar recente ontwikkelingen in de kunstmatige intelligentie. Hoewel de metafoor van het brein als computer zinvol kan zijn in wetenschappelijk onderzoek en het academische debat schiet ze ernstig te kort. Zo laat AI-onderzoeker David Watson in een wetenschappelijke publicatie in het vakbladMinds and Machines(2019) zien dat de overeenkomsten tussen menselijke intelligentie en kunstmatige intelligentie in zowel het academische als het publieke discours schromelijk worden overdreven. Dat komt doordat wij ten onrechte menselijke kenmerken als bewustzijn, intuïtie en empathie op computers projecteren.
Wie goed oplet ziet ook het omgekeerde gebeuren: techbedrijven projecteren computereigenschappen op mensen. Door bewustzijn, intelligentie, waarneming, intuïtie, empathie en persoonlijkheid te verschralen tot kwantificeerbare verschijnselen en dataverwerkingsprocessen kunnen techbedrijven makkelijker claimen dat ze deze aspecten kunnen nabouwen met hun eigen computersystemen.
Ook de derde stap, 'Silicon Valley maakt betere computers', is misleidend. Wanneer we het leven beschouwen als een wedstrijdje rekenkracht en wiskundig modelleren klopt deze bewering: dan leggen wij het, inderdaad, onherroepelijk af tegen de supercomputers van Silicon Valley. Maar niet alles wat wij in het leven belangrijk vinden is berekenbaar en dataficeerbaar. Intelligentie is meer dan wiskundig modelleren. Dat de rekenkracht van onze machines exponentieel is toegenomen, betekent niet dat intelligentie ook exponentieel is toegenomen. Computers voeren taken uit zonder enige vorm van mentaal begrip, zintuiglijke waarneming, bewustzijn, empathie en intentie. Desondanks zijn we door onze historische verafgoding van kwantificeerbaarheid, binaire logica en beheersbaarheid steeds meer aspecten van ons leven gaan uitbesteden aan computerlogica.
Als we een probleem willen oplossen zoeken we het antwoord eerder in de ontwerpvraag welk soort computers we willen dan in de vraag welk soort samenleving we willen. Daarmee zijn we beland bij de vierde stap: we richten ons tot bedrijven die een 'ethisch alternatief' beloven te bieden voor de technologie van Big Tech. Bijvoorbeeld een app die onze schermtijd bijhoudt of een sociale-mediaplatform zonder algoritmisch gecureerde tijdlijn.
Deze 'humane technologie', veelal ontworpen vanuit het principe'ethics by design',laat zien dat we ondanks het gepiep en gekraak van de technologische beheersdroom nog altijd geloven dat betere technologie tot een betere wereld zal leiden. Terwijl de oplossing niet zozeer ligt in betere technologie, maar in een betererelatiemet technologie. Een relatie waarin we technologie niet gebruiken als duizenddingendoekje voor maatschappelijke problemen, maar een relatie waarin we het mensbeeld van waaruit wij technologie vormgeven actief blijven bevragen en wijzigen.
Er is nog een andere sturende krachtte bedenken die onze relatie met technologie in hoge mate bepaalt, namelijk ons hardnekkige verlangen naar eenwording. Enerzijds eenwording met onszelf: zolang jij het algoritme eert met volmaakte data-offers eert het algoritme jou met een diepe reiniging van je sociale-media-feed. Onwelgevallige berichten worden voor je opgeschoond zodat je comfortabel kunt samenvallen met je eigen wereldbeeld. Hebben algoritmen op basis van jouw zoek- en like-gedrag bijvoorbeeld vastgesteld dat je politiek links georiënteerd zou zijn? Dan is de kans kleiner dat je in je zoekresultaten en sociale-mediatijdlijn rechts georiënteerde berichten zult aantreffen. Zoals Geoff Huston het noemt, internetpionier van het eerste uur, is het hedendaagse internet niet veel meer dan een'gigantic vanity-reinforcing distorted TikTok selfie'.
Anderzijds streven we naar eenwording met elkaar: als iedereen zijn auto, huis, stad, fitbit, vaccinatiepaspoort, digitale identiteit, wandelroute, stofzuiger, koelkast, kind en brein aansluit op hetinternet of everythingdoet de collectieve intelligentie van het zelflerende systeem de rest. Dan weten we precies hoe we alle verkeersstromen, mensenmassa's, publieke voorzieningen, gezondheidszorg en CO2-uitstoot moeten verdelen. Er is genoeg statistisch gecalculeerd geluk voor iedereen!
Alex Pentland (mit) is iemand die heilig in deze belofte gelooft. Samen met een team van onderzoekers en ontwikkelaars werkt hij aan een menselijke simulatie van een zelflerend computersysteem: we moeten het voor ons zien als een'hive-mind',waar, zo beschrijft hij in zijn boekSocial Physics(2015), 'elk element leert in contact met andere elementen waardoor gedragspatronen ontstaan die optimaal door bedrijven en overheden voorspeld en gestuurd kunnen worden'. Net zoals zelfrijdende auto's optimale efficiency en veiligheid beloven zolang ze in een netwerk met elkaar kunnen communiceren, belooft de hive-mind optimale veiligheid, gezondheid en duurzaamheid zolang we onze data maar aan elkaar koppelen en onze gedragspatronen op basis van calculatie op elkaar afstemmen. Sociaal vertrouwen en politieke besluitvorming kunnen wat Pentland betreft de prullenbak in; de hive-mind berekent hoe we ons moeten gedragen om tot het meest optimale resultaat voor iedereen te komen:hive-mind for president!
Een belangrijke denkfout in dit beheersoptimisme, los van alle technische obstakels en ethische privacy- en autonomiebezwaren, is de misvatting dat de mensheid goed gedijt bij eenwording. Wat ingrijpende ontwikkelingen zoals de oorlog in Oekraïne, de coronapandemie en de hive-mind met elkaar gemeen hebben, is dat ze het gevolg zijn van een radicaal streven naar eenheid, waarin alle vormen van andersheid worden opgeslokt. Wie om zich heen kijkt, ziet de destructieve uitwerking van het eenheidsstreven op meerdere plekken. Bijvoorbeeld in Poetins eenheid van kerk en staat en zijn streven naar een ondeelbare Russische natie. Maar ook in het eenheidsideaal van de wereld als eenglobal villagemet vlieg- en vaarroutes die alles met elkaar in verbinding hebben gebracht, waardoor ecologische destructie en woekerende virussen toenemen. En in het eenheidsideaal van een collectief geboosterd immuunsysteem dat van elk individu hetzelfde groene vaccinatievinkje eist alvorens men deel mag nemen aan de samenleving:either you are with us or you are with the wappies!
Het probleem met deze eenheidsidealen, of ze zich nu uiten in vaccinatiedrang of almaar uitdijende datakoppelingen, is dat ze streven naar het opheffen van grenzen, waardoor we uiteindelijk de oorlog verklaren aan onderlinge verschillen. Dat leidt tot maatschappelijke homogenisering, onderdrukking en intellectuele stilstand. In het streven naar eenheid wordt immers 'het Andere' binnengehaald en vervolgens tot hetzelfde gemaakt om bij die eenheid te horen. Daarmee heffen we 'de Ander' op. Dat is gevaarlijk omdat de mens juist bestaat bij de gratie van een andersheid waartoe ze zich kan verhouden.
Zonder de Ander kunnen wij onszelf niet zien en niet verder ontwikkelen.
De filosoof Jan Drost beschrijft inHet romantisch misverstand(2011) hoe wij ook in de liefde deze eenheidsfout maken: 'Wij hebben geleerd liefde als eenheid te zien. Beter zouden we de liefde begrijpen als tweeheid. Een liefdesrelatie vindt altijd plaatstussenmensen en daar is altijd meer dan één voor nodig.'
Het niet kunnen kennen van de Ander, en deonmogelijkheid om de Ander volledig om te zetten in kennis is een voorwaarde om een leven lang door te kunnen blijven gaan met kennismaken; een voorwaarde om een tweeheid te kunnen zijn in plaats van een eenheid waarin de nieuwsgierigheid naar de Ander verdwijnt. Een belangrijke les uit het boek van Drost die hij ontleent aan de filosoof Emmanuel Levinas is dan ook dat we de andersheid van de Ander niet moeten opheffen door het Andere tot hetzelfde te maken of de Ander tot ik te maken. Het is een belangrijke les die we ook te leren hebben in onze relatie met technologie. In plaats van te streven naar eenwording met technologie moeten we de andersheid van technologie omarmen en een relatie met technologie aangaan die ruimte biedt voor een tweeheid in plaats van een eenheid. Dat betekent dat we haar niet moeten reduceren tot een frictieloos middel ter zelfbevestiging, en niet moeten gebruiken om ons eigen mensbeeld te consolideren.
Het beste medicijn tegen destructieve eenwording en technologische beheerswaan is een herziening van de beelden van waaruit wij technologie vormgeven.
We hebben altijd grenzen nodig, en een zekere afstand om onszelf, elkaar en onze omgeving vanuit nieuwsgierigheid te kunnen waarnemen en actief te kunnen vormgeven. Met technologie zouden we die afstand niet moeten opheffen, maar juist moeten faciliteren. Als we onszelf als interactieve beeldvormers leren kennen, ontstaat ruimte om ons behavioristische mensbeeld te leren herkennen, kritisch te onderhandelen en van daaruit andere technologie scheppende mogelijkheden aan te gaan. Zolang wij binnen de vormen van ons zelf opgelegde behavioristische mensbeeld blijven bewegen, en onze datagestuurde medemens deze beelden niet meer uitdaagt, riskeren wij opgesloten te raken in ons robotische zelfbeeld. Iemand moet dus in dat zelfbeeld porren, om te voorkomen dat we elke dag hetzelfde blijven zien en hetzelfde blijven doen en tegelijk een ander, beter resultaat verwachten. Zonder andere blik geen ander resultaat.
Techbedrijven hebben een probleem gecreëerd dat alleen zij met een 'humaner' ontwerp van hun technologie kunnen oplossen